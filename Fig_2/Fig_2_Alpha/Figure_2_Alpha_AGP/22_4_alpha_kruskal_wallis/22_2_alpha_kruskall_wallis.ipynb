{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:Center; color:orange;\">- BIOM Analysis -</h1>\n",
    "<h1 style=\"text-align:center; color:black;\">------------------------------------------------------------------------------</h1>\n",
    "<h4 style=\"text-align:center; color:blue;\">Andrew W. Brooks</h4>\n",
    "<h4 style=\"text-align:center; color:blue;\">Vanderbilt Genetics Institute</h4>\n",
    "<h4 style=\"text-align:center; color:blue;\">andrew.w.brooks(at)vanderbilt.edu</h4>\n",
    "<h1 style=\"text-align:center; color:black;\">------------------------------------------------------------------------------</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from biom import load_table\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "######################################################################################\n",
    "##### USER INPUT #####################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfIn = pd.read_csv(\"22_2_collate_alpha_1000_81000_5000/shannon.txt\", sep='\\t', index_col=None,engine='python', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = dfIn[dfIn[\"sequences per sample\"] == 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df1[df1.columns[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'10317.000002503', u'10317.000013618', u'10317.000031796',\n",
       "       u'10317.000026504', u'10317.000007104', u'10317.000007077',\n",
       "       u'10317.000016408', u'10317.000005802', u'10317.000006952',\n",
       "       u'10317.000013023', \n",
       "       ...\n",
       "       u'10317.000001654', u'10317.000011375', u'10317.000042586',\n",
       "       u'10317.000041282', u'10317.000001208', u'10317.000027729',\n",
       "       u'10317.000013573', u'10317.000010544', u'10317.000005878',\n",
       "       u'10317.000012987'],\n",
       "      dtype='object', length=1375)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.convert_objects(convert_numeric=True).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(columns=df2.columns, index=[\"Mean\"])\n",
    "for i in df2.convert_objects(convert_numeric=True).columns:\n",
    "    #print i, df2[i].astype(float).mean()\n",
    "    x[i] = df2[i].astype(float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10317.000002503</th>\n",
       "      <th>10317.000013618</th>\n",
       "      <th>10317.000031796</th>\n",
       "      <th>10317.000026504</th>\n",
       "      <th>10317.000007104</th>\n",
       "      <th>10317.000007077</th>\n",
       "      <th>10317.000016408</th>\n",
       "      <th>10317.000005802</th>\n",
       "      <th>10317.000006952</th>\n",
       "      <th>10317.000013023</th>\n",
       "      <th>...</th>\n",
       "      <th>10317.000001654</th>\n",
       "      <th>10317.000011375</th>\n",
       "      <th>10317.000042586</th>\n",
       "      <th>10317.000041282</th>\n",
       "      <th>10317.000001208</th>\n",
       "      <th>10317.000027729</th>\n",
       "      <th>10317.000013573</th>\n",
       "      <th>10317.000010544</th>\n",
       "      <th>10317.000005878</th>\n",
       "      <th>10317.000012987</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>5.234787</td>\n",
       "      <td>6.366268</td>\n",
       "      <td>6.180711</td>\n",
       "      <td>5.858434</td>\n",
       "      <td>5.598638</td>\n",
       "      <td>5.633328</td>\n",
       "      <td>6.161</td>\n",
       "      <td>4.366205</td>\n",
       "      <td>5.656045</td>\n",
       "      <td>5.763796</td>\n",
       "      <td>...</td>\n",
       "      <td>3.258558</td>\n",
       "      <td>2.527899</td>\n",
       "      <td>6.107339</td>\n",
       "      <td>4.795678</td>\n",
       "      <td>4.060061</td>\n",
       "      <td>5.719675</td>\n",
       "      <td>5.950429</td>\n",
       "      <td>2.183108</td>\n",
       "      <td>0.72349</td>\n",
       "      <td>4.569603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      10317.000002503  10317.000013618  10317.000031796  10317.000026504  \\\n",
       "Mean         5.234787         6.366268         6.180711         5.858434   \n",
       "\n",
       "      10317.000007104  10317.000007077  10317.000016408  10317.000005802  \\\n",
       "Mean         5.598638         5.633328            6.161         4.366205   \n",
       "\n",
       "      10317.000006952  10317.000013023       ...         10317.000001654  \\\n",
       "Mean         5.656045         5.763796       ...                3.258558   \n",
       "\n",
       "      10317.000011375  10317.000042586  10317.000041282  10317.000001208  \\\n",
       "Mean         2.527899         6.107339         4.795678         4.060061   \n",
       "\n",
       "      10317.000027729  10317.000013573  10317.000010544  10317.000005878  \\\n",
       "Mean         5.719675         5.950429         2.183108          0.72349   \n",
       "\n",
       "      10317.000012987  \n",
       "Mean         4.569603  \n",
       "\n",
       "[1 rows x 1375 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Importing Mapping File - \n"
     ]
    }
   ],
   "source": [
    "### PATH TO MAPPING FILE ###\n",
    "mapPath = \"30_0_map_trimmed.txt\"\n",
    "\n",
    "##### IMPORT MAPPING FILE #####\n",
    "def load_map(mapPathIn):\n",
    "    print \" - Importing Mapping File - \"\n",
    "    mapDfIn = pd.read_csv(mapPathIn, sep='\\t', index_col=None, skiprows=0, verbose=False)\n",
    "    return mapDfIn.set_index(\"#SampleID\")\n",
    "mapDf = load_map(mapPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:center; color:blue;\">Without Rarefaction Inflation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian or Pacific Islander\n",
      "  Count        : 88\n",
      "  Average Alpha: 4.87992270229\n",
      "African American\n",
      "  Count        : 13\n",
      "  Average Alpha: 4.87024597081\n",
      "Caucasian\n",
      "  Count        : 1237\n",
      "  Average Alpha: 5.31661337805\n",
      "Hispanic\n",
      "  Count        : 37\n",
      "  Average Alpha: 5.61113089289\n",
      "\n",
      "Test Stat      -    P-value\n",
      "(37.98717006987772, 2.8442081191384018e-08)\n"
     ]
    }
   ],
   "source": [
    "alpha = {}\n",
    "for i in x:\n",
    "    raceIn = mapDf[\"race\"][str(i)]\n",
    "    if raceIn not in alpha.keys(): alpha[raceIn] = []\n",
    "    alpha[raceIn].extend(x[i].astype('float'))\n",
    "for i in alpha.keys():\n",
    "    print i\n",
    "    print \"  Count        : \" + str(len(alpha[i]))\n",
    "    print \"  Average Alpha: \" + str(np.mean(alpha[i]))\n",
    "print \"\\nTest Stat      -    P-value\"\n",
    "print stats.kruskal(alpha[\"Asian or Pacific Islander\"], alpha[\"African American\"], alpha[\"Caucasian\"], alpha[\"Hispanic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "###################### WITHOUT ROUNDING TO ONE DECIMAL PLACE #################################\n",
      "##############################################################################################\n",
      "Asian or Pacific Islander - African American\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 88 | List #2 Length: 13\n",
      "    Values 1:5 in list #1: [4.3399837082191999, 5.4690898845573006, 5.6441114337517995, 4.5985001611831002]\n",
      "    Values 1:5 in list #2: [4.4401350361455005, 6.0528632337629995, 4.9297746196245003, 5.3152234834489995]\n",
      "    Test Statistic: 562.0\n",
      "    P-Value (onetailed): 0.461625757224\n",
      "    P-Value (twotailed): 0.923251514448\n",
      "\n",
      "Asian or Pacific Islander - Caucasian\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 88 | List #2 Length: 1237\n",
      "    Values 1:5 in list #1: [4.3399837082191999, 5.4690898845573006, 5.6441114337517995, 4.5985001611831002]\n",
      "    Values 1:5 in list #2: [5.2347872360850998, 6.3662682100744998, 6.1807109045274, 5.8584339657286]\n",
      "    Test Statistic: 36056.0\n",
      "    P-Value (onetailed): 5.88315893791e-08\n",
      "    P-Value (twotailed): 1.17663178758e-07\n",
      "\n",
      "Asian or Pacific Islander - Hispanic\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 88 | List #2 Length: 37\n",
      "    Values 1:5 in list #1: [4.3399837082191999, 5.4690898845573006, 5.6441114337517995, 4.5985001611831002]\n",
      "    Values 1:5 in list #2: [5.7230994304017004, 5.2965336039067008, 6.3888538307076006, 5.5666859688948014]\n",
      "    Test Statistic: 759.0\n",
      "    P-Value (onetailed): 1.31918509656e-06\n",
      "    P-Value (twotailed): 2.63837019311e-06\n",
      "\n",
      "African American - Caucasian\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 13 | List #2 Length: 1237\n",
      "    Values 1:5 in list #1: [4.4401350361455005, 6.0528632337629995, 4.9297746196245003, 5.3152234834489995]\n",
      "    Values 1:5 in list #2: [5.2347872360850998, 6.3662682100744998, 6.1807109045274, 5.8584339657286]\n",
      "    Test Statistic: 5338.0\n",
      "    P-Value (onetailed): 0.0184509449572\n",
      "    P-Value (twotailed): 0.0369018899144\n",
      "\n",
      "African American - Hispanic\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 13 | List #2 Length: 37\n",
      "    Values 1:5 in list #1: [4.4401350361455005, 6.0528632337629995, 4.9297746196245003, 5.3152234834489995]\n",
      "    Values 1:5 in list #2: [5.7230994304017004, 5.2965336039067008, 6.3888538307076006, 5.5666859688948014]\n",
      "    Test Statistic: 117.0\n",
      "    P-Value (onetailed): 0.00325981956169\n",
      "    P-Value (twotailed): 0.00651963912338\n",
      "\n",
      "Caucasian - Hispanic\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 1237 | List #2 Length: 37\n",
      "    Values 1:5 in list #1: [5.2347872360850998, 6.3662682100744998, 6.1807109045274, 5.8584339657286]\n",
      "    Values 1:5 in list #2: [5.7230994304017004, 5.2965336039067008, 6.3888538307076006, 5.5666859688948014]\n",
      "    Test Statistic: 17923.0\n",
      "    P-Value (onetailed): 0.0122349129655\n",
      "    P-Value (twotailed): 0.024469825931\n",
      "\n",
      "##############################################################################################\n",
      "######################### ROUNDING TO ONE DECIMAL PLACE ######################################\n",
      "##############################################################################################\n",
      "Asian or Pacific Islander - African American\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 88 | List #2 Length: 13\n",
      "    Values 1:5 in list #1: [4.3, 5.5, 5.6, 4.6]\n",
      "    Values 1:5 in list #2: [4.4, 6.1, 4.9, 5.3]\n",
      "    Test Statistic: 562.5\n",
      "    P-Value (onetailed): 0.463601518905\n",
      "    P-Value (twotailed): 0.927203037809\n",
      "\n",
      "Asian or Pacific Islander - Caucasian\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 88 | List #2 Length: 1237\n",
      "    Values 1:5 in list #1: [4.3, 5.5, 5.6, 4.6]\n",
      "    Values 1:5 in list #2: [5.2, 6.4, 6.2, 5.9]\n",
      "    Test Statistic: 36111.0\n",
      "    P-Value (onetailed): 6.23661890577e-08\n",
      "    P-Value (twotailed): 1.24732378115e-07\n",
      "\n",
      "Asian or Pacific Islander - Hispanic\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 88 | List #2 Length: 37\n",
      "    Values 1:5 in list #1: [4.3, 5.5, 5.6, 4.6]\n",
      "    Values 1:5 in list #2: [5.7, 5.3, 6.4, 5.6]\n",
      "    Test Statistic: 763.0\n",
      "    P-Value (onetailed): 1.43208465813e-06\n",
      "    P-Value (twotailed): 2.86416931626e-06\n",
      "\n",
      "African American - Caucasian\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 13 | List #2 Length: 1237\n",
      "    Values 1:5 in list #1: [4.4, 6.1, 4.9, 5.3]\n",
      "    Values 1:5 in list #2: [5.2, 6.4, 6.2, 5.9]\n",
      "    Test Statistic: 5374.0\n",
      "    P-Value (onetailed): 0.0196445988835\n",
      "    P-Value (twotailed): 0.039289197767\n",
      "\n",
      "African American - Hispanic\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 13 | List #2 Length: 37\n",
      "    Values 1:5 in list #1: [4.4, 6.1, 4.9, 5.3]\n",
      "    Values 1:5 in list #2: [5.7, 5.3, 6.4, 5.6]\n",
      "    Test Statistic: 118.5\n",
      "    P-Value (onetailed): 0.00355906391194\n",
      "    P-Value (twotailed): 0.00711812782388\n",
      "\n",
      "Caucasian - Hispanic\n",
      "Mann Whitney U - Nonparametric Rank Test\n",
      "    List #1 Length: 1237 | List #2 Length: 37\n",
      "    Values 1:5 in list #1: [5.2, 6.4, 6.2, 5.9]\n",
      "    Values 1:5 in list #2: [5.7, 5.3, 6.4, 5.6]\n",
      "    Test Statistic: 17912.5\n",
      "    P-Value (onetailed): 0.0120115174892\n",
      "    P-Value (twotailed): 0.0240230349783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################################\n",
    "### Function - Mann-Whitney U Test - Nonparametric rank test of lists\n",
    "# Null hypothesis: two samples from the same population \n",
    "# Alternative hypothesis: one population tends to have larger values than the other [Wikipedia]\n",
    "# N samples is > 20 and you have 2 independent samples of ranks (can be unequal lengths) [Scipy]\n",
    "# For two tailed test multiply P-Value*2\n",
    "import scipy.stats as sp\n",
    "# IN: Two independent lists of floats\n",
    "# OUT: Mann Whitney Test Statistic and P-Value\n",
    "def list_mannwhitney(l1, l2, outFile=None):\n",
    "    # use_continuity = Whether a continuity correction (1/2.) should be taken into account. Default is True. [Scipy]\n",
    "    outMann = sp.mannwhitneyu(l1, l2, use_continuity=True)\n",
    "    print \"Mann Whitney U - Nonparametric Rank Test\"\n",
    "    if outFile != None: outFile.write(\"Mann Whitney U - Nonparametric Rank Test\" + \"\\n\")\n",
    "    print \"    List #1 Length: \"+str(len(l1))+\" | List #2 Length: \"+str(len(l2))\n",
    "    print \"    Values 1:5 in list #1: \" + str(l1[0:4])\n",
    "    print \"    Values 1:5 in list #2: \" + str(l2[0:4])\n",
    "    if outFile != None: outFile.write(\"    List #1 Length: \"+str(len(l1))+\" | List #2 Length: \"+str(len(l2)) + \"\\n\")\n",
    "    print \"    Test Statistic: \"+str(outMann[0])\n",
    "    if outFile != None: outFile.write(\"    Test Statistic: \"+str(outMann[0]) + \"\\n\")\n",
    "    print \"    P-Value (onetailed): \"+str(outMann[1])\n",
    "    if outFile != None: outFile.write(\"    P-Value (onetailed): \"+str(outMann[1]) + \"\\n\")\n",
    "    print \"    P-Value (twotailed): \"+str(outMann[1]*2)\n",
    "    if outFile != None: outFile.write(\"    P-Value (twotailed): \"+str(outMann[1]*2) + \"\\n\")\n",
    "    return outMann\n",
    "##################################################################################\n",
    "#alpha[\"Asian or Pacific Islander\"], alpha[\"African American\"], alpha[\"Caucasian\"], alpha[\"Hispanic\"]\n",
    "\n",
    "print \"##############################################################################################\"\n",
    "print \"###################### WITHOUT ROUNDING TO ONE DECIMAL PLACE #################################\"\n",
    "print \"##############################################################################################\"\n",
    "\n",
    "print \"Asian or Pacific Islander\" + \" - \" + \"African American\"\n",
    "list_mannwhitney(alpha[\"Asian or Pacific Islander\"],alpha[\"African American\"])\n",
    "print\n",
    "print \"Asian or Pacific Islander\" + \" - \" + \"Caucasian\"\n",
    "list_mannwhitney(alpha[\"Asian or Pacific Islander\"],alpha[\"Caucasian\"])\n",
    "print\n",
    "print \"Asian or Pacific Islander\" + \" - \" + \"Hispanic\"\n",
    "list_mannwhitney(alpha[\"Asian or Pacific Islander\"],alpha[\"Hispanic\"])\n",
    "print\n",
    "print \"African American\" + \" - \" + \"Caucasian\"\n",
    "list_mannwhitney(alpha[\"African American\"],alpha[\"Caucasian\"])\n",
    "print\n",
    "print \"African American\" + \" - \" + \"Hispanic\"\n",
    "list_mannwhitney(alpha[\"African American\"],alpha[\"Hispanic\"])\n",
    "print\n",
    "print \"Caucasian\" + \" - \" + \"Hispanic\"\n",
    "list_mannwhitney(alpha[\"Caucasian\"],alpha[\"Hispanic\"])\n",
    "print\n",
    "\n",
    "print \"##############################################################################################\"\n",
    "print \"######################### ROUNDING TO ONE DECIMAL PLACE ######################################\"\n",
    "print \"##############################################################################################\"\n",
    "\n",
    "alpha2 = {}\n",
    "alpha2[\"Asian or Pacific Islander\"] = [ round(elem, 1) for elem in alpha[\"Asian or Pacific Islander\"] ]\n",
    "alpha2[\"African American\"] = [ round(elem, 1) for elem in alpha[\"African American\"] ]\n",
    "alpha2[\"Caucasian\"] = [ round(elem, 1) for elem in alpha[\"Caucasian\"] ]\n",
    "alpha2[\"Hispanic\"] = [ round(elem, 1) for elem in alpha[\"Hispanic\"] ]\n",
    "\n",
    "print \"Asian or Pacific Islander\" + \" - \" + \"African American\"\n",
    "list_mannwhitney(alpha2[\"Asian or Pacific Islander\"],alpha2[\"African American\"])\n",
    "print\n",
    "print \"Asian or Pacific Islander\" + \" - \" + \"Caucasian\"\n",
    "list_mannwhitney(alpha2[\"Asian or Pacific Islander\"],alpha2[\"Caucasian\"])\n",
    "print\n",
    "print \"Asian or Pacific Islander\" + \" - \" + \"Hispanic\"\n",
    "list_mannwhitney(alpha2[\"Asian or Pacific Islander\"],alpha2[\"Hispanic\"])\n",
    "print\n",
    "print \"African American\" + \" - \" + \"Caucasian\"\n",
    "list_mannwhitney(alpha2[\"African American\"],alpha2[\"Caucasian\"])\n",
    "print\n",
    "print \"African American\" + \" - \" + \"Hispanic\"\n",
    "list_mannwhitney(alpha2[\"African American\"],alpha2[\"Hispanic\"])\n",
    "print\n",
    "print \"Caucasian\" + \" - \" + \"Hispanic\"\n",
    "list_mannwhitney(alpha2[\"Caucasian\"],alpha2[\"Hispanic\"])\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileOut = open('22_2_alpha_kw_hispanic.txt', 'w')\n",
    "for item in alpha[\"Hispanic\"]:\n",
    "    fileOut.write(\"%s\\n\" % item)\n",
    "fileOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileOut = open('22_2_alpha_kw_african_american.txt', 'w')\n",
    "for item in alpha[\"African American\"]:\n",
    "    fileOut.write(\"%s\\n\" % item)\n",
    "fileOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileOut = open('22_2_alpha_kw_asian.txt', 'w')\n",
    "for item in alpha[\"Asian or Pacific Islander\"]:\n",
    "    fileOut.write(\"%s\\n\" % item)\n",
    "fileOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileOut = open('22_2_alpha_kw_caucasian.txt', 'w')\n",
    "for item in alpha[\"Caucasian\"]:\n",
    "    fileOut.write(\"%s\\n\" % item)\n",
    "fileOut.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:center; color:blue;\">With Rarefaction Inflation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asian or Pacific Islander\n",
      "  Count        : 8800\n",
      "  Average Alpha: 4.87992270229\n",
      "African American\n",
      "  Count        : 1300\n",
      "  Average Alpha: 4.87024597081\n",
      "Caucasian\n",
      "  Count        : 123700\n",
      "  Average Alpha: 5.31661337805\n",
      "Hispanic\n",
      "  Count        : 3700\n",
      "  Average Alpha: 5.61113089289\n",
      "\n",
      "Test Stat      -     P-value\n",
      "(3770.3667625389644, 0.0)\n"
     ]
    }
   ],
   "source": [
    "alpha = {}\n",
    "for i in df2:\n",
    "    raceIn = mapDf[\"race\"][str(i)]\n",
    "    if raceIn not in alpha.keys(): alpha[raceIn] = []\n",
    "    alpha[raceIn].extend(df2[i].astype('float'))\n",
    "for i in alpha.keys():\n",
    "    print i\n",
    "    print \"  Count        : \" + str(len(alpha[i]))\n",
    "    print \"  Average Alpha: \" + str(np.mean(alpha[i]))\n",
    "print \"\\nTest Stat      -     P-value\"\n",
    "print stats.kruskal(alpha[\"Asian or Pacific Islander\"], alpha[\"African American\"], alpha[\"Caucasian\"], alpha[\"Hispanic\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
